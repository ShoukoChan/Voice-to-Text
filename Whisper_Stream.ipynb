{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "614ca997-ddd8-45dc-92c2-288bbb1ec338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 12 00:04:53 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 552.12                 Driver Version: 552.12         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650      WDDM  |   00000000:02:00.0 Off |                  N/A |\n",
      "| N/A   40C    P8              2W /   30W |       0MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      2788    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A      4384    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A      8356    C+G   ...1.0_x64__w2gh52qy24etm\\Nahimic3.exe      N/A      |\n",
      "|    0   N/A  N/A      9704    C+G   ....0_x64__8wekyb3d8bbwe\\HxOutlook.exe      N/A      |\n",
      "|    0   N/A  N/A      9864    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     10528    C+G   ...312.0_x64__dt26b99r8h8gj\\RtkUWP.exe      N/A      |\n",
      "|    0   N/A  N/A     12508    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A     16136    C+G   ...0_x64__8wekyb3d8bbwe\\HxAccounts.exe      N/A      |\n",
      "|    0   N/A  N/A     17628    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     23560    C+G   ...on\\125.0.2535.67\\msedgewebview2.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#Checking for availability of GPU + specifications\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bc9d12-6a0d-4120-9b1c-6e8e9bd9a7cd",
   "metadata": {},
   "source": [
    "#\n",
    "## Fine - Tuning Whisper with HuggingFace Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64b26d4-1c82-4019-95a4-cdad72de5df4",
   "metadata": {},
   "source": [
    "Transformers have come up as a promising alternative, offering pre-trained parameters and fine-tuning capabilities. The Whisper model by OpenAI is trained on extensive multilingual data, has become a benchmark for ASR. This incorporation leverages the transformer's self-attention mechanism to process temporal sequences in audio data, providing extensive improvements over conventional models in terms of parallelizable training and handling long-term dependencies.\n",
    "This model is also highly effective for noise robustness and language support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e43ad4b-739a-40d3-bdcc-243228360f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg-python in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (0.2.0)\n",
      "Requirement already satisfied: future in c:\\python311\\lib\\site-packages (from ffmpeg-python) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "#Suite for handling multimedia files and streams\n",
    "!pip install ffmpeg-python --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59b59740-de7b-453e-9a2a-21cf4084017f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/datasets\n",
      "  Cloning https://github.com/huggingface/datasets to c:\\users\\shiva\\appdata\\local\\temp\\pip-req-build-pjspgi_a\n",
      "  Resolved https://github.com/huggingface/datasets to commit af3acfdfcf76bb980dbac871540e30c2cade0cf9\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: filelock in c:\\python311\\lib\\site-packages (from datasets==2.19.3.dev0) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python311\\lib\\site-packages (from datasets==2.19.3.dev0) (1.24.3)\n",
      "Collecting pyarrow>=15.0.0 (from datasets==2.19.3.dev0)\n",
      "  Using cached pyarrow-16.1.0-cp311-cp311-win_amd64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\python311\\lib\\site-packages (from datasets==2.19.3.dev0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\python311\\lib\\site-packages (from datasets==2.19.3.dev0) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\python311\\lib\\site-packages (from datasets==2.19.3.dev0) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\python311\\lib\\site-packages (from datasets==2.19.3.dev0) (2.32.3)\n",
      "Collecting tqdm>=4.66.3 (from datasets==2.19.3.dev0)\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: xxhash in c:\\python311\\lib\\site-packages (from datasets==2.19.3.dev0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.19.3.dev0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in c:\\python311\\lib\\site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets==2.19.3.dev0) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.19.3.dev0) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in c:\\python311\\lib\\site-packages (from datasets==2.19.3.dev0) (0.23.3)\n",
      "Requirement already satisfied: packaging in c:\\python311\\lib\\site-packages (from datasets==2.19.3.dev0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from datasets==2.19.3.dev0) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets==2.19.3.dev0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets==2.19.3.dev0) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python311\\lib\\site-packages (from aiohttp->datasets==2.19.3.dev0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python311\\lib\\site-packages (from aiohttp->datasets==2.19.3.dev0) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python311\\lib\\site-packages (from aiohttp->datasets==2.19.3.dev0) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.21.2->datasets==2.19.3.dev0) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.32.2->datasets==2.19.3.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.32.2->datasets==2.19.3.dev0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests>=2.32.2->datasets==2.19.3.dev0) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.32.2->datasets==2.19.3.dev0) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.66.3->datasets==2.19.3.dev0) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets==2.19.3.dev0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas->datasets==2.19.3.dev0) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\python311\\lib\\site-packages (from pandas->datasets==2.19.3.dev0) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.19.3.dev0) (1.16.0)\n",
      "Using cached pyarrow-16.1.0-cp311-cp311-win_amd64.whl (25.9 MB)\n",
      "Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Building wheels for collected packages: datasets\n",
      "  Building wheel for datasets (pyproject.toml): started\n",
      "  Building wheel for datasets (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for datasets: filename=datasets-2.19.3.dev0-py3-none-any.whl size=524354 sha256=46747faeee4ee80ae22d0e83840d0a0c88d66e0333815ec63f87f3c3c9b1a3a5\n",
      "  Stored in directory: C:\\Users\\shiva\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-0b256_33\\wheels\\28\\38\\ed\\9d30df2a8b9ce204de544016db7433552e3ca2eae7c54af26e\n",
      "Successfully built datasets\n",
      "Installing collected packages: tqdm, pyarrow, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.1\n",
      "    Uninstalling tqdm-4.66.1:\n",
      "      Successfully uninstalled tqdm-4.66.1\n",
      "  Rolling back uninstall of tqdm\n",
      "  Moving to c:\\python311\\lib\\site-packages\\tqdm-4.66.1.dist-info\\\n",
      "   from C:\\Python311\\Lib\\site-packages\\~qdm-4.66.1.dist-info\n",
      "  Moving to c:\\python311\\lib\\site-packages\\tqdm\\\n",
      "   from C:\\Python311\\Lib\\site-packages\\~qdm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/datasets 'C:\\Users\\shiva\\AppData\\Local\\Temp\\pip-req-build-pjspgi_a'\n",
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'C:\\\\Python311\\\\Scripts\\\\tqdm.exe' -> 'C:\\\\Python311\\\\Scripts\\\\tqdm.exe.deleteme'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to c:\\users\\shiva\\appdata\\local\\temp\\pip-req-build-jur1gjdr\n",
      "  Resolved https://github.com/huggingface/transformers to commit 35a6d9d6483d4d4d7cd817ed4ecfd5f86e1f9a23\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: filelock in c:\\python311\\lib\\site-packages (from transformers==4.42.0.dev0) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\python311\\lib\\site-packages (from transformers==4.42.0.dev0) (0.23.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python311\\lib\\site-packages (from transformers==4.42.0.dev0) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python311\\lib\\site-packages (from transformers==4.42.0.dev0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.42.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\python311\\lib\\site-packages (from transformers==4.42.0.dev0) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\python311\\lib\\site-packages (from transformers==4.42.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\python311\\lib\\site-packages (from transformers==4.42.0.dev0) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\python311\\lib\\site-packages (from transformers==4.42.0.dev0) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\python311\\lib\\site-packages (from transformers==4.42.0.dev0) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.42.0.dev0) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.42.0.dev0) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers==4.42.0.dev0) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers==4.42.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers==4.42.0.dev0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests->transformers==4.42.0.dev0) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers==4.42.0.dev0) (2024.2.2)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml): started\n",
      "  Building wheel for transformers (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for transformers: filename=transformers-4.42.0.dev0-py3-none-any.whl size=9156712 sha256=72a095ab639c97190ffad960f978b26f79a6b37faeb2c0b4b3aa2acadd240cbd\n",
      "  Stored in directory: C:\\Users\\shiva\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-1fias604\\wheels\\04\\a3\\f1\\b88775f8e1665827525b19ac7590250f1038d947067beba9fb\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.41.2\n",
      "    Uninstalling transformers-4.41.2:\n",
      "      Successfully uninstalled transformers-4.41.2\n",
      "  Rolling back uninstall of transformers\n",
      "  Moving to c:\\python311\\lib\\site-packages\\transformers-4.41.2.dist-info\\\n",
      "   from C:\\Python311\\Lib\\site-packages\\~ransformers-4.41.2.dist-info\n",
      "  Moving to c:\\python311\\lib\\site-packages\\transformers\\\n",
      "   from C:\\Python311\\Lib\\site-packages\\~ransformers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers 'C:\\Users\\shiva\\AppData\\Local\\Temp\\pip-req-build-jur1gjdr'\n",
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'C:\\\\Python311\\\\Scripts\\\\transformers-cli.exe' -> 'C:\\\\Python311\\\\Scripts\\\\transformers-cli.exe.deleteme'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (0.10.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\python311\\lib\\site-packages (from librosa) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\python311\\lib\\site-packages (from librosa) (1.11.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\python311\\lib\\site-packages (from librosa) (1.3.0)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\python311\\lib\\site-packages (from librosa) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from librosa) (0.59.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\python311\\lib\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from librosa) (1.8.1)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from librosa) (4.8.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from librosa) (1.0.7)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from numba>=0.51.0->librosa) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from pooch>=1.0->librosa) (4.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python311\\lib\\site-packages (from pooch>=1.0->librosa) (23.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\python311\\lib\\site-packages (from pooch>=1.0->librosa) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python311\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\python311\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\python311\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2024.2.2)\n",
      "Requirement already satisfied: jiwer in c:\\python311\\lib\\site-packages (3.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from jiwer) (8.1.6)\n",
      "Requirement already satisfied: rapidfuzz<4,>=3 in c:\\python311\\lib\\site-packages (from jiwer) (3.9.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from click<9.0.0,>=8.1.3->jiwer) (0.4.6)\n",
      "Requirement already satisfied: gradio in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (4.36.1)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from gradio) (5.3.0)\n",
      "Requirement already satisfied: fastapi in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from gradio) (0.111.0)\n",
      "Requirement already satisfied: ffmpy in c:\\python311\\lib\\site-packages (from gradio) (0.3.2)\n",
      "Requirement already satisfied: gradio-client==1.0.1 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from gradio) (1.0.1)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\python311\\lib\\site-packages (from gradio) (0.23.3)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from gradio) (6.4.0)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\python311\\lib\\site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\python311\\lib\\site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from gradio) (3.7.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\python311\\lib\\site-packages (from gradio) (1.24.3)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from gradio) (3.10.3)\n",
      "Requirement already satisfied: packaging in c:\\python311\\lib\\site-packages (from gradio) (23.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\python311\\lib\\site-packages (from gradio) (2.0.3)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\python311\\lib\\site-packages (from gradio) (10.0.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from gradio) (2.7.3)\n",
      "Requirement already satisfied: pydub in c:\\python311\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from gradio) (0.0.9)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\python311\\lib\\site-packages (from gradio) (0.4.8)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\python311\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\python311\\lib\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from gradio) (0.12.3)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from gradio) (4.8.0)\n",
      "Requirement already satisfied: urllib3~=2.0 in c:\\python311\\lib\\site-packages (from gradio) (2.0.6)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from gradio) (0.30.1)\n",
      "Requirement already satisfied: fsspec in c:\\python311\\lib\\site-packages (from gradio-client==1.0.1->gradio) (2024.2.0)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in c:\\python311\\lib\\site-packages (from gradio-client==1.0.1->gradio) (11.0.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from altair<6.0,>=4.2.0->gradio) (4.21.1)\n",
      "Requirement already satisfied: toolz in c:\\python311\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from httpx>=0.24.1->gradio) (4.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from httpx>=0.24.1->gradio) (3.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\python311\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
      "Requirement already satisfied: requests in c:\\python311\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\python311\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (4.66.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib~=3.0->gradio) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib~=3.0->gradio) (4.42.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\python311\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from pydantic>=2.0->gradio) (2.18.4)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.6)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\python311\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\python311\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from fastapi->gradio) (0.37.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from fastapi->gradio) (0.0.4)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in c:\\python311\\lib\\site-packages (from fastapi->gradio) (5.10.0)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from fastapi->gradio) (2.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from email_validator>=2.0.0->fastapi->gradio) (2.6.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.34.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\python311\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.17.2)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\python311\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio) (1.0.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio) (0.22.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Requirement already satisfied: more-itertools in c:\\python311\\lib\\site-packages (10.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/datasets\n",
    "!pip install git+https://github.com/huggingface/transformers\n",
    "!pip install librosa --user\n",
    "!pip install evaluate>=0.3.0 --user\n",
    "!pip install jiwer --user\n",
    "!pip install gradio --user\n",
    "!pip install more-itertools --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a8fed6e-55ac-4b28-aaa4-7462ed281ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a4dbef0ea14ef19effe01717aed3fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Linking to HuggingFace Hub using access token\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0c9fea-1683-4fa8-b2a2-f314e902d58b",
   "metadata": {},
   "source": [
    "#\n",
    "-- Dataset: Mozilla CommonVoice - English\n",
    "\n",
    "- Whisper has 5 configurations with different model sizes\n",
    "- Using Whisper 'small' model as per available computing power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce4ca8f7-0c23-457a-8287-96475a406307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import interleave_datasets, load_dataset\n",
    "\n",
    "def load_streaming_dataset(dataset_name, dataset_config_name, split, **kwargs):\n",
    "    '''\n",
    "    Streaming mode for loading data progressively while iterating over dataset.\n",
    "\n",
    "    Function downloads fragments of data and combines (concatenation) multiple of them.\n",
    "    '''\n",
    "    if \"+\" in split:\n",
    "        # load multiple splits with streaming mode\n",
    "        dataset_splits = [load_dataset(dataset_name, dataset_config_name, split=split_name, streaming=True, **kwargs) for split_name in split.split(\"+\")]\n",
    "        # interleave to form one dataset\n",
    "        interleaved_dataset = interleave_datasets(dataset_splits)\n",
    "        return interleaved_dataset\n",
    "    else:\n",
    "        # single split with streaming mode\n",
    "        dataset = load_dataset(dataset_name, dataset_config_name, split=split, streaming=True, **kwargs)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5862f330-9612-457e-92ed-1058f02f17f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiva\\AppData\\Roaming\\Python\\Python311\\site-packages\\datasets\\load.py:2552: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shiva\\AppData\\Roaming\\Python\\Python311\\site-packages\\datasets\\load.py:2552: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import IterableDatasetDict\n",
    "\n",
    "raw_datasets = IterableDatasetDict()\n",
    "\n",
    "\n",
    "raw_datasets[\"train\"] = load_streaming_dataset(\"mozilla-foundation/common_voice_11_0\", \"en\", split=\"train\", use_auth_token=True, trust_remote_code=True)\n",
    "raw_datasets[\"test\"] = load_streaming_dataset(\"mozilla-foundation/common_voice_11_0\", \"en\", split=\"test\", use_auth_token=True, trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa398c62-0b1d-472e-883e-826a93483f67",
   "metadata": {},
   "source": [
    "##\n",
    "AUDIO PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c06cc5f-e158-462e-a237-ccf1eb3bdd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'client_id': Value(dtype='string', id=None),\n",
       " 'path': Value(dtype='string', id=None),\n",
       " 'audio': Audio(sampling_rate=48000, mono=True, decode=True, id=None),\n",
       " 'sentence': Value(dtype='string', id=None),\n",
       " 'up_votes': Value(dtype='int64', id=None),\n",
       " 'down_votes': Value(dtype='int64', id=None),\n",
       " 'age': Value(dtype='string', id=None),\n",
       " 'gender': Value(dtype='string', id=None),\n",
       " 'accent': Value(dtype='string', id=None),\n",
       " 'locale': Value(dtype='string', id=None),\n",
       " 'segment': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import WhisperProcessor\n",
    "\n",
    "# Whisper Processor works as feature extractor and tokenizer which performs audio pre-processing and further processes text token\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"English\", task=\"transcribe\")\n",
    "\n",
    "raw_datasets[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "617c4e06-5d20-422b-a6d4-1a97b77f9f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "\n",
    "raw_datasets = raw_datasets.cast_column(\"audio\", Audio(sampling_rate=16000)) #sampling rate for Whisper\n",
    "\n",
    "from transformers.models.whisper.english_normalizer import BasicTextNormalizer\n",
    "\n",
    "do_lower_case = False\n",
    "do_remove_punctuation = False\n",
    "\n",
    "normalizer = BasicTextNormalizer()\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    #log-Mel Spectrogram: input features\n",
    "    batch[\"input_features\"] = processor.feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    batch[\"input_length\"] = len(audio[\"array\"]) / audio[\"sampling_rate\"]\n",
    "\n",
    "    #pre-processing\n",
    "    transcription = batch[\"sentence\"]\n",
    "    if do_lower_case:\n",
    "        transcription = transcription.lower()\n",
    "    if do_remove_punctuation:\n",
    "        transcription = re.sub(punctuation_to_remove_regex, \" \", transcription).strip()\n",
    "\n",
    "    batch[\"labels\"] = processor.tokenizer(transcription).input_ids # target text -> label id\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04fe5b83-e9da-4c62-99d7-a01fc22565f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepearing Dataset for Training\n",
    "vectorized_datasets = raw_datasets.map(prepare_dataset, remove_columns=list(next(iter(raw_datasets.values())).features)).with_format(\"torch\")\n",
    "\n",
    "vectorized_datasets[\"train\"] = vectorized_datasets[\"train\"].shuffle(\n",
    "    buffer_size=300,\n",
    "    seed=0)\n",
    "\n",
    "max_input_length = 15.0\n",
    "\n",
    "def is_audio_in_length_range(length):\n",
    "    return length < max_input_length\n",
    "\n",
    "vectorized_datasets[\"train\"] = vectorized_datasets[\"train\"].filter(\n",
    "    is_audio_in_length_range,\n",
    "    input_columns=[\"input_length\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52817d40-bf90-4a32-aae9-375a9265c4ba",
   "metadata": {},
   "source": [
    "##\n",
    "TRAINING PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21817792-1b3d-4c36-be0c-0ec9927c0419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    ''' Data Collator prepares PyTorch tensors for the model'''\n",
    "\n",
    "    processor: Any\n",
    "    \n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels as per length -> Torch Tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # padding to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78d0cd17-760e-4a44-b5a4-fa44e86cf309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WER (Word Error Rate) Metric\n",
    "\n",
    "import evaluate\n",
    "metric = evaluate.load(\"wer\")\n",
    "\n",
    "do_normalize_eval = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bc3110a-b866-4edd-adcd-d4d01029fe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    if do_normalize_eval:\n",
    "        pred_str = [normalizer(pred) for pred in pred_str]\n",
    "        label_str = [normalizer(label) for label in label_str]\n",
    "\n",
    "        pred_str = [pred_str[i] for i in range(len(pred_str)) if len(label_str[i]) > 0]\n",
    "        label_str = [label_str[i] for i in range(len(label_str)) if len(label_str[i]) > 0]\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "    return {\"wer\":wer}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a6cf8b-df0d-4fcc-a5e2-b05fbd8cd254",
   "metadata": {},
   "source": [
    "#\n",
    "LOADING WHISPER 'SMALL' CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce167d40-aac2-43bf-b07f-000fb83c9db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
    "\n",
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9a64cff-ce2c-4c71-a530-d120a7e1d133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\python311\\lib\\site-packages (4.41.2)\n",
      "Requirement already satisfied: filelock in c:\\python311\\lib\\site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\python311\\lib\\site-packages (from transformers[torch]) (0.23.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python311\\lib\\site-packages (from transformers[torch]) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python311\\lib\\site-packages (from transformers[torch]) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\python311\\lib\\site-packages (from transformers[torch]) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\python311\\lib\\site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\python311\\lib\\site-packages (from transformers[torch]) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\python311\\lib\\site-packages (from transformers[torch]) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\python311\\lib\\site-packages (from transformers[torch]) (4.66.1)\n",
      "Requirement already satisfied: torch in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from transformers[torch]) (2.3.1+cu118)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from transformers[torch]) (0.31.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\python311\\lib\\site-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\python311\\lib\\site-packages (from torch->transformers[torch]) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\python311\\lib\\site-packages (from torch->transformers[torch]) (3.1.2)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from torch->transformers[torch]) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers[torch]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests->transformers[torch]) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers[torch]) (2024.2.2)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->transformers[torch]) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->transformers[torch]) (2021.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python311\\lib\\site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\python311\\lib\\site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: accelerate in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (0.31.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python311\\lib\\site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python311\\lib\\site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (2.3.1+cu118)\n",
      "Requirement already satisfied: huggingface-hub in c:\\python311\\lib\\site-packages (from accelerate) (0.23.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\python311\\lib\\site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in c:\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.10.0->accelerate) (2021.4.0)\n",
      "Requirement already satisfied: requests in c:\\python311\\lib\\site-packages (from huggingface-hub->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\python311\\lib\\site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python311\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\python311\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('4.41.2', '0.31.0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install transformers[torch]\n",
    "!pip install -U accelerate\n",
    "import accelerate\n",
    "import transformers\n",
    "\n",
    "transformers.__version__, accelerate.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f30dc3b2-53e2-4cc9-a8af-19825941bb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1+cu118\n",
      "True\n",
      "CUDA version: 11.8\n",
      "0\n",
      "NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806abc20-491d-4fa5-9937-5e8634b4d076",
   "metadata": {},
   "source": [
    "#\n",
    "DETAILS OF TRAINING PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a4690d3-fb09-49ee-829a-101777fc13ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./Whisper-Small\",\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=100,\n",
    "    max_steps=1000,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=200,\n",
    "    eval_steps=200,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e58fc345-c246-4bd7-ae91-330e683f74bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "from transformers.trainer_pt_utils import IterableDatasetShard\n",
    "from torch.utils.data import IterableDataset\n",
    "'''\n",
    "Callbacks can customize and inspect the behaviour of training loop in Trainer - PyTorch\n",
    "'''\n",
    "class ShuffleCallback(TrainerCallback):\n",
    "    def on_epoch_begin(self, args, state, control, train_dataloader, **kwargs):\n",
    "        if isinstance(train_dataloader.dataset, IterableDatasetShard):\n",
    "            pass\n",
    "        elif isinstance(train_dataloader.dataset, IterableDataset):\n",
    "            train_dataloader.dataset.set_epoch(train_dataloader.dataset._epoch + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c862502-032e-421a-9aa0-0c757eec0459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=vectorized_datasets[\"train\"],\n",
    "    eval_dataset=vectorized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor,\n",
    "    callbacks=[ShuffleCallback()],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4167793-c2c9-4f49-844a-d4ab1581d2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    }
   ],
   "source": [
    "#For non-default generation parameters set in model config (warning)\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    max_length=448,\n",
    "    suppress_tokens=[],\n",
    "    begin_suppress_tokens=[220, 50257]\n",
    ")\n",
    "\n",
    "model.save_pretrained(training_args.output_dir)\n",
    "processor.save_pretrained(training_args.output_dir)\n",
    "generation_config.save_pretrained(training_args.output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e4980c-6e35-4c5a-842c-6e62e593d571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 948736it [01:10, 13540.75it/s]\n",
      "C:\\Users\\shiva\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "C:\\Python311\\Lib\\site-packages\\transformers\\models\\whisper\\modeling_whisper.py:691: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   4/1000 04:46 < 39:38:45, 0.01 it/s, Epoch 0.00/9223372036854775807]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd2bd1d-f698-401e-97dd-5e085bf8d90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74a0695-48e1-422e-b92c-5fae5243d2ce",
   "metadata": {},
   "source": [
    "## Building a Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0936e85-579d-42fa-94fb-cb95a8880bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import gradio as gr\n",
    "\n",
    "pipe = pipeline(model=\"Shangyy/Whisper-Small\")\n",
    "\n",
    "def transcribe(audio):\n",
    "    text = pipe(audio)[\"text\"]\n",
    "    return text\n",
    "\n",
    "#Gradio - Microphone transcription (Another block can be added for separate file uploads)\n",
    "demo = gr.Interface(\n",
    "    fn=transcribe,\n",
    "    inputs=gr.Audio(source=\"microphone\", type=\"filepath\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Voice-to-Text System\",\n",
    "    description=\"Realtime demo for transcribing spoken language into text.\",\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
